include:
  # stt
  - ../../module/stt_npu/docker-compose.yml
  # ipex-llm-ollama
  - ../../module/ipex-llm-ollama/docker-compose.yml
  # tts
  - ../../module/tts/docker-compose.yml  

services:  
  open-webui:
    image: ghcr.io/open-webui/open-webui
    container_name: open-webui
    restart: always
    ports:
      - "8080:8080"
    volumes:
      - ./.cache/open-webui:/app/backend/data
    environment:
      - http_proxy=${http_proxy:-}
      - https_proxy=${https_proxy:-}
      - no_proxy=stt,tts,melotts,ipex-llm-ollama,localhost,127.0.0.1
      - OLLAMA_BASE_URL=http://ipex-llm-ollama:11434
      - AUDIO_STT_ENGINE=openai
      - AUDIO_STT_MODEL=whisper-1
      - AUDIO_STT_OPENAI_API_BASE_URL=http://stt:9000/v1
      - AUDIO_STT_OPENAI_API_KEY=no-need
      - AUDIO_TTS_ENGINE=openai
      - AUDIO_TTS_MODEL=tts-1
      - AUDIO_TTS_OPENAI_API_BASE_URL=http://tts:8000/v1
      - AUDIO_TTS_OPENAI_API_KEY=no-need
      - AUDIO_TTS_SPLIT_ON=punctuation
      - AUDIO_TTS_VOICE=echo

networks:
  app-network:
